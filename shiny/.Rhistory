}
nonUniquenames=stringr::str_replace(nonUniqueSetnames, pattern = "_non_unique_intersect_counts_relative_sorted.bed", replacement = "")
printbackgroundnonUnique=data.frame(x=backgroundnonUniquenmd)
printbackgroundnonUnique=as.data.frame(t(printbackgroundnonUnique))
rownames(printbackgroundnonUnique)=nonUniquenames
nonUniquenames
printbackgroundnonUnique
nonUniquenmddataframes
View(nonUniquenmddataframes)
backgroundnonUniquenmd
nonUniquenames
shiny::runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
shiny::runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
for(i in lengths){
for(j in i){
print(j)
}
}
library(ggplot2)
library(ggsignif)
splitTranscripts=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/split-ORF_Transcripts_length.tsv',
sep = '\t', header = FALSE)
splitlengths=splitTranscripts[,2]
nonSplitTranscriptss=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/non-split-ORF_Transcripts_length.tsv',
sep = '\t', header = FALSE)
nonsplitlengths=nonSplitTranscriptss[,2]
lengths=c("split-ORF encoding NMD Transcripts"=list(splitlengths), "Remaining NMD Transcripts" = list(nonsplitlengths))
#boxplot(lengths)
test=data.frame(matrix(NA, nrow = length(lengths[[2]]), ncol = 2))
for(i in lengths){
for(j in i){
print(j)
}
}
for(i in lengths){
c=1
for(j in i){
test[i,c]=j
c=c+1
}
}
test=data.frame(matrix(NA, nrow = length(lengths[[2]]), ncol = 2))
for(i in lengths){
c=1
for(j in i){
test[i,c]=j
c=c+1
}
}
test
test=data.frame(matrix(NA, nrow = length(lengths[[2]]), ncol = 2))
test[,1]
length(lengths)
test=data.frame(matrix(NA, nrow = length(lengths[[2]]), ncol = 2))
for(i in length(lengths)){
c=1
for(j in i){
test[c,i]=j
c=c+1
}
}
test
test=data.frame(matrix(NA, nrow = length(lengths[[2]]), ncol = 2))
c=1
for(i in lengths){
r=1
for(j in i){
test[r,c]=j
r=r+1
}
c=c+1
}
test
lengthframe=data.frame(matrix(NA, nrow = length(lengths[[2]]), ncol = 2))
c=1
for(i in lengths){
r=1
for(j in i){
lengthframe[r,c]=j
r=r+1
}
c=c+1
}
colnames(lengthframe)=names(lengths)
colnames(lengthframe)
ggplot(lengthframe, aes(x=colnames(lengthframe), y=lengthframe[,1:2])) +
geom_boxplot()
ggplot(lengthframe +
geom_boxplot())
ggplot(lengthframe$`split-ORF encoding NMD Transcripts` +
geom_boxplot())
splitTranscripts=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/split-ORF_Transcripts_length.tsv',
sep = '\t', header = FALSE)
splitlengths=splitTranscripts[,2]
nonSplitTranscriptss=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/non-split-ORF_Transcripts_length.tsv',
sep = '\t', header = FALSE)
nonsplitlengths=nonSplitTranscriptss[,2]
lengths=c("split-ORF encoding NMD Transcripts"=list(splitlengths), "Remaining NMD Transcripts" = list(nonsplitlengths))
boxplot(lengths)
splitTranscriptsDense=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/split-ORF_Transcripts_met_density.tsv',
sep = '\t', header = FALSE)
splitdensities=splitTranscriptsDense[,2]
nonSplitTranscriptsDense=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/non-split-ORF_Transcripts_met_density.tsv',
sep = '\t', header = FALSE)
nonsplitdensities=nonSplitTranscriptsDense[,2]
densities=c("split-ORF encoding NMD Transcripts"=list(splitlengths), "Remaining NMD Transcripts" = list(nonsplitlengths))
boxplot(densities)
splitTranscriptsDense=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/split-ORF_Transcripts_met_density.tsv',
sep = '\t', header = FALSE)
splitdensities=splitTranscriptsDense[,2]
nonSplitTranscriptsDense=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/non-split-ORF_Transcripts_met_density.tsv',
sep = '\t', header = FALSE)
nonsplitdensities=nonSplitTranscriptsDense[,2]
densities=c("split-ORF encoding NMD Transcripts"=list(splitdensities), "Remaining NMD Transcripts" = list(nonsplitdensities))
boxplot(densities)
?t.test()
t.test(densities[1],densities[2])
densities[1]
t.test(densities[[1]],densities[[2]])
#knitr::opts_chunk$set(echo = TRUE)
splitTranscripts=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/split-ORF_Transcripts_length.tsv',
sep = '\t', header = FALSE)
splitlengths=splitTranscripts[,2]
nonSplitTranscripts=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/non-split-ORF_Transcripts_length.tsv',
sep = '\t', header = FALSE)
nonsplitlengths=nonSplitTranscripts[,2]
lengths=c("split-ORF encoding NMD Transcripts"=list(splitlengths), "Remaining NMD Transcripts" = list(nonsplitlengths))
splitTranscriptsDense=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/split-ORF_Transcripts_met_density.tsv',
sep = '\t', header = FALSE)
splitdensities=splitTranscriptsDense[,2]
nonSplitTranscriptsDense=read.table(
file = 'G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/Output/run_11.02.2021-13.21.38_new_NMD/non-split-ORF_Transcripts_met_density.tsv',
sep = '\t', header = FALSE)
nonsplitdensities=nonSplitTranscriptsDense[,2]
densities=c("split-ORF encoding NMD Transcripts"=list(splitdensities), "Remaining NMD Transcripts" = list(nonsplitdensities))
boxplot(lengths)
t.test(lengths[[1]],lengths[[2]])
?boxplot()
boxplot(lengths,ylab="Transcript cDNA length")
shiny::runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
setwd("G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase/data/RI/BOWTIE")
setwd("G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase/data/RI/BOWTIE")
minReadnum=2
ridirectories=list.dirs(path = ".", full.names = TRUE, recursive = TRUE)
rifiles=list()
risetnames=list()
for(i in ridirectories){
if(!(identical(list.files(i,pattern="*RI_intersect_counts_relative_sorted.bed"), character(0)))){
rifiles=c(rifiles,paste0(i,"/",list.files(i,pattern="*RI_intersect_counts_relative_sorted.bed")))
risetnames=c(risetnames,list.files(i,pattern="*RI_intersect_counts_relative_sorted.bed"))
}
}
ridataframes <- lapply(rifiles, read.csv,header = FALSE,sep="\t")
rilist=list()
for(a in ridataframes){
a$V1=paste0(a$V1,":",a$V4)
a$V4=NULL
rilist=c(rilist,list(a))
}
ridataframes=rilist
names(ridataframes) <- stringr::str_replace(risetnames, pattern = "_intersect_counts_relative_sorted.bed", replacement = "")
rirelevantregionscount=list()
rirelevantregions=list()
i=1
for(riframe in ridataframes){
colnames(riframe)=c("ID","start","stop","read_count", "relative_count")
temp2=0
c=1
for(count2 in riframe$relative_count){
if(count2>=thresholdri[[i]]){
if(riframe$read_count[[c]] >= minReadnum){
temp2 = temp2 + 1
}
}
c = c + 1
}
i = i + 1
rirelevantregionscount = c(rirelevantregionscount,temp2)
}
ridirectories=list.dirs(path = ".", full.names = TRUE, recursive = TRUE)
randomrifiles=list()
for(i in ridirectories){
if(!(identical(list.files(i,pattern="*RI_random_3UTR_intersect_counts_relative_sorted.bed"), character(0)))){
randomrifiles=c(randomrifiles,paste0(i,"/",list.files(i,pattern="*RI_random_3UTR_intersect_counts_relative_sorted.bed")))
}
}
randomridataframes <- lapply(randomrifiles, read.csv,header = FALSE,sep="\t")
backgroundri=list()
for(randomriframe in randomridataframes){
colnames(randomriframe)=c("ID","start","stop","read_count", "relative_count")
temp2=t.test(randomriframe$relative_count)[[4]][[2]]
backgroundri = c(backgroundri,temp2)
}
randomRiSetnames=list()
for(i in ridirectories){
if(!(identical(list.files(i,pattern="*RI_random_3UTR_intersect_counts_relative_sorted.bed"), character(0)))){
randomRiSetnames=c(randomRiSetnames,list.files(i,pattern="*RI_random_3UTR_intersect_counts_relative_sorted.bed"))
}
}
randomRinames=stringr::str_replace(randomRiSetnames, pattern = "_random_3UTR_intersect_counts_relative_sorted.bed", replacement = "")
printbackgroundRI=data.frame(x=backgroundri)
printbackgroundRI=as.data.frame(t(printbackgroundRI))
rownames(printbackgroundRI)=randomRinames
colnames(printbackgroundRI)="Threshold"
print(kable(printbackgroundRI, caption="Thresholds for each dataset"))
thresholdri=backgroundri
ridirectories=list.dirs(path = ".", full.names = TRUE, recursive = TRUE)
randomrifiles=list()
for(i in ridirectories){
if(!(identical(list.files(i,pattern="*RI_random_3UTR_intersect_counts_relative_sorted.bed"), character(0)))){
randomrifiles=c(randomrifiles,paste0(i,"/",list.files(i,pattern="*RI_random_3UTR_intersect_counts_relative_sorted.bed")))
}
}
randomridataframes <- lapply(randomrifiles, read.csv,header = FALSE,sep="\t")
backgroundri=list()
for(randomriframe in randomridataframes){
colnames(randomriframe)=c("ID","start","stop","read_count", "relative_count")
if(is.na(t.test(randomriframe$relative_count)[[4]][[2]])){
temp2=0
}
else{
temp2=t.test(randomriframe$relative_count)[[4]][[2]]
}
backgroundri = c(backgroundri,temp2)
}
randomRiSetnames=list()
for(i in ridirectories){
if(!(identical(list.files(i,pattern="*RI_random_3UTR_intersect_counts_relative_sorted.bed"), character(0)))){
randomRiSetnames=c(randomRiSetnames,list.files(i,pattern="*RI_random_3UTR_intersect_counts_relative_sorted.bed"))
}
}
randomRinames=stringr::str_replace(randomRiSetnames, pattern = "_random_3UTR_intersect_counts_relative_sorted.bed", replacement = "")
printbackgroundRI=data.frame(x=backgroundri)
printbackgroundRI=as.data.frame(t(printbackgroundRI))
rownames(printbackgroundRI)=randomRinames
colnames(printbackgroundRI)="Threshold"
print(kable(printbackgroundRI, caption="Thresholds for each dataset"))
thresholdri=backgroundri
ridirectories=list.dirs(path = ".", full.names = TRUE, recursive = TRUE)
rifiles=list()
risetnames=list()
for(i in ridirectories){
if(!(identical(list.files(i,pattern="*RI_intersect_counts_relative_sorted.bed"), character(0)))){
rifiles=c(rifiles,paste0(i,"/",list.files(i,pattern="*RI_intersect_counts_relative_sorted.bed")))
risetnames=c(risetnames,list.files(i,pattern="*RI_intersect_counts_relative_sorted.bed"))
}
}
ridataframes <- lapply(rifiles, read.csv,header = FALSE,sep="\t")
rilist=list()
for(a in ridataframes){
a$V1=paste0(a$V1,":",a$V4)
a$V4=NULL
rilist=c(rilist,list(a))
}
ridataframes=rilist
names(ridataframes) <- stringr::str_replace(risetnames, pattern = "_intersect_counts_relative_sorted.bed", replacement = "")
rirelevantregionscount=list()
rirelevantregions=list()
i=1
for(riframe in ridataframes){
colnames(riframe)=c("ID","start","stop","read_count", "relative_count")
temp2=0
c=1
for(count2 in riframe$relative_count){
if(count2>=thresholdri[[i]]){
if(riframe$read_count[[c]] >= minReadnum){
temp2 = temp2 + 1
}
}
c = c + 1
}
i = i + 1
rirelevantregionscount = c(rirelevantregionscount,temp2)
}
rimaxsize = max(unlist(rirelevantregionscount)) + 200
riprintframe=data.frame(x=rirelevantregionscount)
riprintframe=as.data.frame(t(riprintframe))
rownames(riprintframe)=names(ridataframes)
colnames(riprintframe)=paste0("Number of unique regions with relative count >= Threshold")
print(kable(riprintframe, caption="Regions above the threshold"))
runApp('G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase')
shiny::runApp()
library('knitr')
maxquantORFs=scan("MaxQuant_uniqueRegionOrfs.csv",what = character())
minReadnum=2
setwd("G:/Justin_Backup_29.04.2020/Justin/Uni-Frankfurt/FP+Masterarbeit/PipeTest/Pipeline/shiny/splitORFdatabase/data/NMD/BOWTIE")
directories<-list.dirs(path = ".", full.names = TRUE, recursive = TRUE)
randomnmdfiles=list()
for(i in directories){
if(!(identical(list.files(i,pattern="*NMD_random_3UTR_intersect_counts_relative_sorted.bed"), character(0)))){
randomnmdfiles=c(randomnmdfiles,paste0(i,"/",list.files(i,pattern="*NMD_random_3UTR_intersect_counts_relative_sorted.bed")))
}
}
randomnmddataframes <- lapply(randomnmdfiles, read.csv,header = FALSE,sep="\t")
backgroundnmd=list()
for(randomframe in randomnmddataframes){
colnames(randomframe)=c("ID","start","stop","read_count", "relative_count")
temp=t.test(randomframe$relative_count)[[4]][[2]]
backgroundnmd = c(backgroundnmd,temp)
}
randomSetnames=list()
for(i in directories){
if(!(identical(list.files(i,pattern="*NMD_random_3UTR_intersect_counts_relative_sorted.bed"), character(0)))){
randomSetnames=c(randomSetnames,list.files(i,pattern="*NMD_random_3UTR_intersect_counts_relative_sorted.bed"))
}
}
randomnames=stringr::str_replace(randomSetnames, pattern = "_random_3UTR_intersect_counts_relative_sorted.bed", replacement = "")
printbackground=data.frame(x=backgroundnmd)
printbackground=as.data.frame(t(printbackground))
rownames(printbackground)=randomnames
colnames(printbackground)="Threshold"
print(kable(printbackground, caption="Thresholds for each dataset"))
threshold=backgroundnmd
names(threshold)=names(nmddataframes)
runApp()
names(threshold)=names(randomnmddataframes)
directories=list.dirs(path = ".", full.names = TRUE, recursive = TRUE)
nmdfiles=list()
setnames=list()
for(i in directories){
if(!(identical(list.files(i,pattern="*NMD_intersect_counts_relative_sorted.bed"), character(0)))){
nmdfiles=c(nmdfiles,paste0(i,"/",list.files(i,pattern="*NMD_intersect_counts_relative_sorted.bed")))
setnames=c(setnames,list.files(i,pattern="*NMD_intersect_counts_relative_sorted.bed"))
}
}
nmddataframes <- lapply(nmdfiles, read.csv,header = FALSE,sep="\t")
nmdlist=list()
for(a in nmddataframes){
a$V1=paste0(a$V1,":",a$V4)
a$V4=NULL
nmdlist=c(nmdlist,list(a))
}
nmddataframes=nmdlist
names(nmddataframes) <- stringr::str_replace(setnames, pattern = "_intersect_counts_relative_sorted.bed", replacement = "")
relevantregionscount=list()
relevantregions=list()
i=1
for(frame in nmddataframes){
colnames(frame)=c("ID","start","stop","read_count", "relative_count")
temp=0
c=1
for(count in frame$relative_count){
if(count>=threshold[[i]]){
if(frame$read_count[[c]] >= minReadnum){
temp = temp + 1
}
}
c = c + 1
}
i = i + 1
relevantregionscount = c(relevantregionscount,temp)
}
maxsize = max(unlist(relevantregionscount)) + 200
printframe=data.frame(x=relevantregionscount)
printframe=as.data.frame(t(printframe))
rownames(printframe)=names(nmddataframes)
colnames(printframe)=paste0("Number of unique regions with relative count >= threshold")
print(kable(printframe, caption="Regions above the threshold"))
library("dplyr")
library("UpSetR")
library("knitr")
is.integer0 <- function(x){
is.integer(x) && length(x) == 0L
}
upsetlist=list()
j=1
for(f in nmddataframes){
bed=f
list<- rep(NA, length(bed[,1]))
for(i in 1:length(bed[,1])){
list[i]=paste0(bed[i,1],":",bed[i,2],":",bed[i,3])
}
rownames(bed)=list
bed = filter(bed, V6 > threshold[[j]])
bed = filter(bed, V5 >= minReadnum)
upsetlist=c(upsetlist,list(row.names(bed)))
colnames(bed)=c("ID","start","stop","read_count", "relative_count")
#print(names(nmddataframes)[j])
#print(bed[1:5,], row.names = FALSE)
if(is.integer0(which(is.na(bed[1:5,1])))){
print(kable(bed[1:5,], caption=names(nmddataframes)[j], row.names = FALSE))
}
else{
end=which(is.na(bed[1:5,1]))-1
print(kable(bed[1:end,], caption=names(nmddataframes)[j], row.names = FALSE))
}
j = j + 1
}
names(upsetlist)=names(nmddataframes)
upset(fromList(upsetlist), order.by = "freq", nsets = 10, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 10, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 10, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
nnintersects = 50,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 10, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
nintersects = 50,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 10, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
nintersects = 60,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 10, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
nintersects = NA,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 10, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
nintersects = NA,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 10, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
nintersects = NA,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
View(bed)
runApp()
upset(fromList(upsetlist), order.by = "freq", nsets = 12, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
nintersects = NA,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 12, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
nintersects = NA,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.25))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 12, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
nintersects = NA,
number.angles = 45,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.25))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 12, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
nintersects = NA,
number.angles = 15,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.25))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 8, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
#nintersects = NA,
#number.angles = 45,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.25))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 8, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
#nintersects = NA,
#number.angles = 45,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 8, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
#nintersects = NA,
#number.angles = 45,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 8, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
#nintersects = NA,
#number.angles = 45,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 8, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
#nintersects = NA,
number.angles = 15,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 8, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
#nintersects = NA,
number.angles = 5,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
upset(fromList(upsetlist), order.by = "freq", nsets = 8, point.size = 2.25, line.size = 1.5, set_size.show = TRUE,
#nintersects = NA,
#number.angles = 5,
set_size.scale_max = maxsize,
mainbar.y.label = "Unique region Intersections", sets.x.label = "Matching unique regions per dataset",
text.scale = c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5))# c(1.5, 1.25, 0.9, 1.25, 1.25, 1.5)c(1, 1, 0.9, 1, 1, 1)
